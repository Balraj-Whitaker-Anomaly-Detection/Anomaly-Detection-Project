{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2617054",
   "metadata": {},
   "source": [
    "## Acquire Data from the SQL DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "750ed3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_curriculum_logs():\n",
    "    \n",
    "    # imports\n",
    "    import os\n",
    "    import env\n",
    "    import pandas as pd\n",
    "    \n",
    "    filename = \"curr_logs.csv\"\n",
    "\n",
    "    if os.path.isfile(filename):\n",
    "        return pd.read_csv(filename, index_col=False)\n",
    "    else:\n",
    "        # read the SQL query into a dataframe\n",
    "        URL = f'mysql+pymysql://{env.user}:{env.password}@{env.host}/curriculum_logs'\n",
    "        SQL = '''\n",
    "        SELECT date, time, path, user_id, cohort_id, program_id, ip,\n",
    "        name, slack, start_date, end_date, created_at, updated_at\n",
    "        FROM logs\n",
    "        JOIN cohorts on logs.cohort_id = cohorts.id\n",
    "        '''\n",
    "        curr_logs = pd.read_sql(SQL, URL)\n",
    "        \n",
    "        # Write that dataframe to cscfor later.\n",
    "        curr_logs.to_csv('curriculum_logs.csv')\n",
    "\n",
    "        return curr_logs \n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad019024",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_logs = get_curriculum_logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4265c4b0",
   "metadata": {},
   "source": [
    "## Acquire and Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef9b941f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_prep_curr_logs():\n",
    "    '''\n",
    "    This function reads data from a csv and prepares is by: \n",
    "    reads from csv\n",
    "    concats date + time \n",
    "    changes date_time to pd datetime\n",
    "    changes date to pd datetime\n",
    "    changes time to pd datetime\n",
    "    sets index to date_time\n",
    "    changes cohort start to datetime\n",
    "    changes cohort end to datetime\n",
    "    label students by the program they are in\n",
    "    create column where true or false if staff\n",
    "    create column with date - end date\n",
    "    drop columns\n",
    "    returns df\n",
    "    '''\n",
    "    \n",
    "    # imports\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    # read from csv\n",
    "    curr_logs = pd.read_csv('curriculum_logs.csv')\n",
    "    \n",
    "    # concat date + time \n",
    "    curr_logs['date_time']=curr_logs.date+' '+curr_logs.time\n",
    "    \n",
    "    # change date_time to pd datetime\n",
    "    curr_logs.date_time = pd.to_datetime(curr_logs.date_time)\n",
    "    \n",
    "    # change date to pd datetime\n",
    "    curr_logs.date = pd.to_datetime(curr_logs.date)\n",
    "    \n",
    "    # change time to pd datetime\n",
    "    curr_logs.time = pd.to_datetime(curr_logs.time)\n",
    "    \n",
    "    # set index to date_time\n",
    "    curr_logs = curr_logs.set_index(curr_logs.date_time)\n",
    "    \n",
    "    # change cohort start to datetime\n",
    "    curr_logs.start_date = pd.to_datetime(curr_logs.start_date)\n",
    "    \n",
    "    # change cohort end to datetime\n",
    "    curr_logs.end_date = pd.to_datetime(curr_logs.end_date)\n",
    "    \n",
    "    # label students by the program they are in\n",
    "    program_id = [curr_logs.program_id == 1, curr_logs.program_id == 2, curr_logs.program_id == 3, curr_logs.program_id == 4]\n",
    "    program = ['php','java','data_science','front_end']\n",
    "    curr_logs['program'] = np.select(program_id, program)\n",
    "    \n",
    "    # create column where true or false if staff\n",
    "    curr_logs['staff'] = curr_logs.name=='Staff'\n",
    "    \n",
    "    # create column with date - end date\n",
    "    curr_logs['days_after_grad'] = curr_logs.date-curr_logs.end_date\n",
    "    \n",
    "    # drop columns\n",
    "    cols_to_drop = ['Unnamed: 0', 'Unnamed: 0.1', 'date', 'time']\n",
    "    curr_logs = curr_logs.drop(columns=cols_to_drop)\n",
    "    \n",
    "    # drop null for path column\n",
    "    curr_logs = curr_logs[curr_logs.path.notnull()]\n",
    "    \n",
    "    return curr_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "559ccd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_logs = get_n_prep_curr_logs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71904d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_logs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b7c543",
   "metadata": {},
   "source": [
    "## Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebb39a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_vars(x): \n",
    "\n",
    "    '''\n",
    "    This function scales variables you want to cluster.\n",
    "    '''\n",
    "\n",
    "    # Scaler import\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "    # create the scaler\n",
    "    scaler = MinMaxScaler().fit(x)\n",
    "    # use the scaler\n",
    "    scaled_array = scaler.transform(x)\n",
    "    scaled_array[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695cd2b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
